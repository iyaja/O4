{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TOKENIZERS_PARLLELISM=false\n",
    "%env WANDB_PROJECT=O4\n",
    "\n",
    "run_name=\"bert-base-high-lr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25667028-1e0f-4800-80be-ecffd6cb2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import compiler_gym                      # imports the CompilerGym environments\n",
    "\n",
    "import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoModelForPreTraining, RobertaForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers import PreTrainedTokenizerFast, BertTokenizerFast, RobertaTokenizerFast\n",
    "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693d918-39e4-4414-a6b8-356d1be2d013",
   "metadata": {},
   "source": [
    "Compiler gym comes with many environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c3757-b650-48b7-93e4-bd768a2c9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler_gym.COMPILER_GYM_ENVS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961dce0-675b-41c0-9bc6-f4429c5eefe0",
   "metadata": {},
   "source": [
    "We are solving phase ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1d45b-e595-4ea8-b749-0b70184eaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"llvm-ic-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d170e8-6d07-4600-b963-8ba0cdb935a2",
   "metadata": {},
   "source": [
    "The actions you can take are applying one among many different optimization passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19f9c4-1943-4ac3-b17d-7a67b7ad1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135de41c-aa78-4f79-b270-0b312d4c221e",
   "metadata": {},
   "source": [
    "At each step, you \"observe\" a string which contains the IR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff555324-d088-49c0-addb-a54e186ad995",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52512e-c547-4c18-9768-9dbdf96f8830",
   "metadata": {},
   "source": [
    "Check which benchmark (program) is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2d7fa-7ea1-4d4f-860b-3dc1326d57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1179f9-60de-46fa-93c7-c45c43d90966",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()                              # starts a new compilation session\n",
    "# env.render()                             # prints the IR of the program\n",
    "env.step(env.action_space.sample())      # applies a random optimization, updates state/reward/actions\n",
    "# env.close()                              # closes the environment, freeing resources\n",
    "# env.observation[\"Ir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7eec4-8073-45ea-a1db-b57a8b68f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592d4c3-92a5-4a74-9caf-399a82456d77",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c4fd6-e8d1-4aa1-8c0c-2b86f6d0f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 10\n",
    "PHASES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef9e4a-757b-42d6-b8ed-588ed22ef45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(samples=SAMPLES, phases=PHASES):\n",
    "    for _ in range(samples):\n",
    "        env.reset()\n",
    "        for phase in range(phases):\n",
    "            action = env.action_space.sample()\n",
    "            _, reward, done, info = env.step(action)\n",
    "            env.action_space.to_string(action)\n",
    "            if done: break\n",
    "            yield env.observation['Ir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdc46f-0bd6-4913-8110-9bef99605fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = ByteLevelBPETokenizer()\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "# tokenizer.train_from_iterator(sampler(), special_tokens=[\"[SEP]\", \"[CLS]\"])\n",
    "# tokenizer.save(\"vocab/tokenizer.json\")\n",
    "# tokenizer.save_model(\"vocab/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c83210-b102-4bcb-8062-1016464aeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the tokenizer\n",
    "# tokenizer._tokenizer.post_processor = BertProcessing((\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")), (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),)\n",
    "# tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55701687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('microsoft/codebert-base-mlm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e59b04-a89d-4f9f-ada4-aaf97193cf3a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4229e30-8823-4f58-a352-73e95ab5d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bd6c7-c485-4492-8221-33399ea21347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_sampler(samples=SAMPLES, phases=PHASES):\n",
    "    for _ in range(samples):\n",
    "        env.reset()\n",
    "        for phase in range(phases):\n",
    "            action = env.action_space.sample()\n",
    "            _, reward, done, info = env.step(action)\n",
    "            if done: break\n",
    "            text = env.action_space.to_string(action) + env.observation['Ir']\n",
    "            label = reward\n",
    "            yield  text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54d2a6-800b-4441-af75-64e67e2d3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [{\"text\": x, \"label\": y} for x, y in dataset_sampler(1000, 20)]\n",
    "valid_samples = [{\"text\": x, \"label\": y} for x, y in dataset_sampler(200, 20)]\n",
    "\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "valid_df = pd.DataFrame(valid_samples)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc9ede-ea08-4bf7-8d20-daedc5135a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b1857-46a4-4c7f-a0d6-716ab22b4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    return tokenizer(example['text'], padding=True, truncation=True)\n",
    "\n",
    "tokenized_train = train_ds.map(preprocess, batched=True)\n",
    "tokenized_valid = valid_ds.map(preprocess, batched=True)\n",
    "\n",
    "columns = ['input_ids', 'label', 'attention_mask']\n",
    "tokenized_train.set_format(type='torch', columns=columns)\n",
    "tokenized_valid.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b97920",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b939878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdecd0-3e11-4c73-bb5f-a532ff85a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "# tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"vocab/tokenizer.json\")\n",
    "# tokenizer = RobertaTokenizerFast.from_pretrained('vocab', max_len=512)\n",
    "# tokenizer = BertTokenizerFast(vocab_file=\"vocab/vocab.json\")\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base-mlm', num_labels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14df42-9a2f-4607-a69b-b6d633304aeb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f70d1-e8d1-4b1e-be72-4c44c05221a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostModelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = nn.MSELoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a41bd-d504-457c-bb59-be994dcdd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"codebert-llvm-ic-v0\",\n",
    ")\n",
    "\n",
    "trainer = CostModelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
