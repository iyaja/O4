{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "956df88c-2a53-48b9-94e1-12acab978c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=O4\n"
     ]
    }
   ],
   "source": [
    "# %env TOKENIZERS_PARLLELISM=false\n",
    "%env WANDB_PROJECT=O4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc3c88d-61fa-4ab0-9f4e-b2266f214509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import compiler_gym                      # imports the CompilerGym environments\n",
    "from compiler_gym.envs.llvm.datasets import CBenchDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoModelForPreTraining, RobertaForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers import PreTrainedTokenizerFast, BertTokenizerFast, RobertaTokenizerFast\n",
    "\n",
    "import tokenizers\n",
    "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer\n",
    "from tokenizers.processors import BertProcessing, RobertaProcessing\n",
    "\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2df26-9896-4fae-b11d-37dd9be7e946",
   "metadata": {},
   "source": [
    "Compiler gym comes with many environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1670da6d-abd0-4253-b4bc-f8adc4a79127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gcc-v0',\n",
       " 'llvm-v0',\n",
       " 'llvm-ic-v0',\n",
       " 'llvm-codesize-v0',\n",
       " 'llvm-autophase-ic-v0',\n",
       " 'llvm-autophase-codesize-v0',\n",
       " 'llvm-ir-ic-v0',\n",
       " 'llvm-ir-codesize-v0',\n",
       " 'loop_tool-v0']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiler_gym.COMPILER_GYM_ENVS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f878df-1f35-4b52-97d1-d0f9946a3e13",
   "metadata": {},
   "source": [
    "We are solving phase ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "223553f0-46e8-4d46-b54a-0b2456f669de",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"llvm-ic-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ab67f-e708-46a1-ae78-88e96873e1a0",
   "metadata": {},
   "source": [
    "The actions you can take are applying one among many different optimization passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498c0466-1a29-4025-959f-09e1763b923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d18c7c88-7fbf-43c0-a686-93e31d8da16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benchmark://cbench-v1/qsort"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475712f3-5756-4771-b3f0-3d2b168a02d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Commandline([-add-discriminators -adce -aggressive-instcombine -alignment-from-assumptions -always-inline -argpromotion -attributor -barrier -bdce -break-crit-edges -simplifycfg -callsite-splitting -called-value-propagation -canonicalize-aliases -consthoist -constmerge -constprop -coro-cleanup -coro-early -coro-elide -coro-split -correlated-propagation -cross-dso-cfi -deadargelim -dce -die -dse -reg2mem -div-rem-pairs -early-cse-memssa -early-cse -elim-avail-extern -ee-instrument -flattencfg -float2int -forceattrs -inline -insert-gcov-profiling -gvn-hoist -gvn -globaldce -globalopt -globalsplit -guard-widening -hotcoldsplit -ipconstprop -ipsccp -indvars -irce -infer-address-spaces -inferattrs -inject-tli-mappings -instsimplify -instcombine -instnamer -jump-threading -lcssa -licm -libcalls-shrinkwrap -load-store-vectorizer -loop-data-prefetch -loop-deletion -loop-distribute -loop-fusion -loop-guard-widening -loop-idiom -loop-instsimplify -loop-interchange -loop-load-elim -loop-predication -loop-reroll -loop-rotate -loop-simplifycfg -loop-simplify -loop-sink -loop-reduce -loop-unroll-and-jam -loop-unroll -loop-unswitch -loop-vectorize -loop-versioning-licm -loop-versioning -loweratomic -lower-constant-intrinsics -lower-expect -lower-guard-intrinsic -lowerinvoke -lower-matrix-intrinsics -lowerswitch -lower-widenable-condition -memcpyopt -mergefunc -mergeicmps -mldst-motion -sancov -name-anon-globals -nary-reassociate -newgvn -pgo-memop-opt -partial-inliner -partially-inline-libcalls -post-inline-ee-instrument -functionattrs -mem2reg -prune-eh -reassociate -redundant-dbg-inst-elim -rpo-functionattrs -rewrite-statepoints-for-gc -sccp -slp-vectorizer -sroa -scalarizer -separate-const-offset-from-gep -simple-loop-unswitch -sink -speculative-execution -slsr -strip-dead-prototypes -strip-debug-declare -strip-nondebug -strip -tailcallelim -mergereturn])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a674f-c76c-46a5-b5c1-1394ecc3dde0",
   "metadata": {},
   "source": [
    "At each step, you \"observe\" a string which contains the IR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d05256-55f2-4e0a-a3a4-95fabc53f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3736767-564a-48ee-aaa9-0380c77896c6",
   "metadata": {},
   "source": [
    "Check which benchmark (program) is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd2e32e-4080-4614-9071-5865240f4e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benchmark://cbench-v1/qsort"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0419566c-18b0-442a-b8b8-ba42e9592cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " 0.07430340557275542,\n",
       " False,\n",
       " {'action_had_no_effect': False, 'new_action_space': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()                              # starts a new compilation session\n",
    "# env.render()                             # prints the IR of the program\n",
    "env.step(env.action_space.sample())      # applies a random optimization, updates state/reward/actions\n",
    "# env.close()                              # closes the environment, freeing resources\n",
    "# env.observation[\"Ir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6022d1c-dc46-4a4d-b1a5-6db0dba8906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObservationView[Autophase, AutophaseDict, Bitcode, BitcodeFile, Buildtime, CpuInfo, Inst2vec, Inst2vecEmbeddingIndices, Inst2vecPreprocessedText, InstCount, InstCountDict, InstCountNorm, InstCountNormDict, Ir, IrInstructionCount, IrInstructionCountO0, IrInstructionCountO3, IrInstructionCountOz, IrSha1, IsBuildable, IsRunnable, ObjectTextSizeBytes, ObjectTextSizeO0, ObjectTextSizeO3, ObjectTextSizeOz, Programl, ProgramlJson, Runtime]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c60025-c880-45cc-8ac8-606cb7b40544",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41bfe7ad-b0de-41cf-846c-1c7e50bcab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 10\n",
    "PHASES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609ee7b1-7cba-4aba-99fd-c1730c7a885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sampler(samples=SAMPLES, phases=PHASES):\n",
    "    for _ in range(samples):\n",
    "        env.reset()\n",
    "        for phase in range(phases):\n",
    "            action = env.action_space.sample()\n",
    "            _, reward, done, info = env.step(action)\n",
    "            env.action_space.to_string(action)\n",
    "            if done: break\n",
    "            yield \"\\n\".join(env.observation['Inst2vecPreprocessedText'])\n",
    "\n",
    "def sampler(samples=SAMPLES, phases=PHASES):\n",
    "    for benchmark in env.datasets[\"cbench-v1\"].benchmarks():\n",
    "        print(benchmark)\n",
    "        for _ in range(samples):\n",
    "            env.reset(benchmark=benchmark)\n",
    "            for phase in range(phases):\n",
    "                action = env.action_space.sample()\n",
    "                _, reward, done, info = env.step(action)\n",
    "                env.action_space.to_string(action)\n",
    "                if done: break\n",
    "                yield env.observation['Inst2vecPreprocessedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efe5ee7-500c-4873-a501-fb4860e33b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import CharDelimiterSplit, Sequence, Split\n",
    "from tokenizers.processors import RobertaProcessing\n",
    "\n",
    "tokenizer = Tokenizer(WordPiece(vocab=env.inst2vec.vocab))\n",
    "tokenizer.pre_tokenizer = CharDelimiterSplit(\"\\n\")\n",
    "# tokenizer.pre_tokenizer = Split(pattern=\"[INST]\", behavior=\"removed\")\n",
    "tokenizer.enable_truncation(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e5455f-44d9-46ff-b3ee-2ee164bb6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokens = [\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\", \"[INST]\"]\n",
    "inst_tokens = list(env.inst2vec.vocab.keys())\n",
    "special_tokens = base_tokens + inst_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a311dc-f9b5-493e-8143-5dd59966bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WordPieceTrainer(\n",
    "    special_tokens=base_tokens ,\n",
    "    vocab_size = len(env.inst2vec.vocab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd11129-6988-4554-bc14-b956407ab341",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22371/2556014785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tokenizer.train_from_iterator(single_sampler(), trainer=trainer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tokenizer.post_processor = RobertaProcessing(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[CLS]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[CLS]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[SEP]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[SEP]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# tokenizer.train_from_iterator(single_sampler(), trainer=trainer)\n",
    "tokenizer.post_processor = RobertaProcessing(\n",
    "    cls=(\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    "    sep=(\"[SEP]\", tokenizer.token_to_id(\"[SEP]\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d35ab0cb-8357-49f2-abde-3adee2071435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30470, 565, 563)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = env.observation['Inst2vecPreprocessedText']\n",
    "joined = \"\\n\".join(sample)\n",
    "tokens = tokenizer.encode(joined).tokens\n",
    "len(joined), len(tokens), len(sample), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0efefeb2-91cd-43fe-ab1b-28c1d868a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6432a4a-279e-4761-837c-857bf07c42d5",
   "metadata": {},
   "source": [
    "## Load into Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "652a8537-b96c-492c-a58d-d4314d427e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1f2e77f2-2164-41b9-94c3-f04110a4decf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file='tokenizer.json', max_len_single_sentence=1024)\n",
    "fast_tokenizer.add_tokens(env.action_space.names)\n",
    "fast_tokenizer.add_special_tokens({\n",
    "    'cls_token': '[CLS]',\n",
    "    'pad_token': '[PAD]',\n",
    "    'sep_token': '[SEP]',\n",
    "})\n",
    "# fast_tokenizer.set_truncation_and_padding(\n",
    "#     padding_strategy='longest',\n",
    "#     truncation_strategy='longest_first',\n",
    "#     stride=0,\n",
    "#     max_length=1024,\n",
    "#     pad_to_multiple_of=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2b21616e-0a76-4a36-a000-b80df2fde780",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = env.action_space.names[env.action_space.sample()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6200ef19-ba30-4572-ab54-c69db4d019d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.convert_tokens_to_ids(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4bf03a52-5124-4e75-b893-17c0cb5a1c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1, 1089,    2,    2,  656,  656,  656,    0,  856,  855,  631,  895,\n",
       "          858,  631,  828,  860,  859,  631,  857,  827,  863,  387,  387,  740,\n",
       "          740,  336,  336,  582,  292,  582,  292,  294,  742,    0,  547,  645,\n",
       "          294,  742,    0,  547,  645,  547,  547,  874,  330,  222,  298,  222,\n",
       "          547,  547,  875,  921,  892,  298,  339,  907,  582,  292,  582,  292,\n",
       "          723,  862,  366,  711,  366,    0,  889,    0,  366,  366,  366,  366,\n",
       "          366,  383,  738,  383,    0,  292,    0,  753,  292,    0,  292,  436,\n",
       "          292,  436,  292,  452,  436,  292,  436,  292,  436,  292,  304,  727,\n",
       "          330,  222,    0,    0,   62,   89,   79,   94,   75,  514,   94,  572,\n",
       "          682,   99,  747,  222,  757,  891,  294,    0,    0,  298,  339,    0,\n",
       "            0,  562,  330,  222,    0,    0,  562,  330,  222,    0,    0,  562,\n",
       "          330,  222,  304,  727,  298,  752,  902,  330,  222,  304,  304,  448,\n",
       "            0,    0,  709,  304,  304,  448,    0,    0,  383,  304,  304,  448,\n",
       "            0,    0,  709,  304,  647,  654,  304,  647,  654,  729,  304,  647,\n",
       "          654,  729,  848,  304,  448,    0,    0,  645,  304,  561,  383,  298,\n",
       "          222,    0,    0,  298,  222,  304,  664,  330,  222,  304,    0,  298,\n",
       "          339,    0,  890,  304,  909,  304,  664,  330,  222,    0,    0,    0,\n",
       "          330,  222,    0,    0,  739,  747,  222,  452,  298,  339,  304,  304,\n",
       "          873,  330,  222,    0,  304,  448,    0,    0,  695,  304,  448,    0,\n",
       "            0,  304,  304,  448,    0,    0,  695,    0,  298,  222,  304,  867,\n",
       "          304,  839,  383,  298,  222,    0,    0,  298,  339,  436,  292,  436,\n",
       "          292,  436,  292,  436,  292,  436,  292,    0,  292,  753,  292,    0,\n",
       "          292,  843,  864,  366,  366,  711,    0,  700,  700,  366,  452,  383,\n",
       "          738,    0,  292,    0,  580,  292,  580,  292,    0,    0,    0,  330,\n",
       "          222,    0,    0,  452,  452,  298,  222,    0,    0,    0,    0,  885,\n",
       "          298,  339,  567,  567,  872,  330,  222,  304,  757,  567,  663,  567,\n",
       "          841,  878,  822,  298,  222,  567,  663,  886,  298,  222,  452,  452,\n",
       "          298,  339,  580,  292,  580,  292,    0,  292,  304,  723,  900,  387,\n",
       "          387,  366,  387,  387,  366,  387,  387,  366,  387,  366,  366,  743,\n",
       "          387,  387,  387,  387,  387,  366,  741,  741,  366,  366,  336,  383,\n",
       "          383,  713,  437,  292,  437,  292,  437,  292,  437,  292,  437,  292,\n",
       "          436,  292,  581,  292,  581,  292,  436,  292,  304,  832,  330,  222,\n",
       "          304,  562,  330,  339,  452,  298,  222,  452,  294,  336,  294,  304,\n",
       "          304,  840,  736,  445,  423,  336,  298,  339,  294,  294,  522,  522,\n",
       "          634,  304,  445,  868,  663,  908,  383,  304,  831,  330,  222,  294,\n",
       "          294,  304,  668,  913,  298,  222,  294,  304,  884,  304,  736,  445,\n",
       "          423,  336,  294,  294,  304,  437,  292,  437,  292,  436,  292,  336,\n",
       "          336,  383,  294,  294,  849,  330,  222,  272,  146,  210,  791,  791,\n",
       "           99,  298,  339,  437,  292,  437,  292,  436,  292,  294,  336,  294,\n",
       "          304,  445,  423,  336,  298,  339,  298,  339,  304,  294,  445,  423,\n",
       "          336,  298,  222,  294,  294,  718,  330,  222,  668,  294,  294,  649,\n",
       "          844,  298,  339,  734,  330,  222,  298,  339,  304,  294,  445,  571,\n",
       "          423,  336,  298,  222,  294,  294,  703,  330,  222,  668,  294,  294,\n",
       "          649,  730,  298,  339,  734,  330,  222,  294,  294,  535,  330,  222,\n",
       "          298,  222,  294,  294,  304,  437,  292,  437,  292,  436,  292,  336,\n",
       "          336,  383,  294,  294,  849,  330,  222,  272,  146,  210,  791,  791,\n",
       "           99,  298,  339,  437,  292,  437,  292,  436,  292,  298,  222,  294,\n",
       "          294,  304,  437,  292,  437,  292,  436,  292,  336,  336,  383,  294,\n",
       "          294,  849,  330,  222,  272,  146,  210,  791,  791,   99,  298,  339,\n",
       "          437,  292,  437,  292,  436,  292,  294,  820,  294,  522,  522,  634,\n",
       "          294,  294,  522,  522,  634,  846,  330,  222,  294,  304,  445,  423,\n",
       "          294,  535,  330,  222,  294,  304,  448,  507,  336,  294,  304,  445,\n",
       "          571,  423,  304,  448,  507,  336,  304,  561,  383,  298,  339,  294,\n",
       "          294,  535,  330,  222,  294,  336,  298,  749,  298,  222,  298,  222,\n",
       "          294,  294,  535,  330,  222,  294,  304,  448,  507,  336,  294,  304,\n",
       "          448,  507,  336,  304,  561,  383,  298,  339,  294,  304,  445,  423,\n",
       "          294,  535,  330,  222,  294,  304,  445,  571,  423,  336,  298,  222,\n",
       "          298,  339,  298,  339,  304,  561,  383,  304,  730,  330,  222,  304,\n",
       "          448,  507,  294,  336,  304,  448,  507,  294,  336,  298,  222,  452,\n",
       "          298,  339,  436,  292,  581,  292,  581,  292,  436,  292,  437,  292,\n",
       "          437,  292,  437,  292,  437,  292,  437,  292,  636,  915,  387,  387,\n",
       "          366,  387,  387,  366,  743,  387,  387,  336,  336,  383,  713,  437,\n",
       "          292,  437,  292,  298,  339,  294,  294,  703,  330,  222,  294,  336,\n",
       "          294,  304,  445,  423,  336,  298,  339,  294,  294,  718,  330,  222,\n",
       "          668,  294,  294,  649,  845,  330,  222,  294,  336,  298,  339,  298,\n",
       "          222,  304,  294,  445,  423,  336,  298,  222,  294,  294,  304,  437,\n",
       "          292,  437,  292,  436,  292,  336,  336,  383,  294,  294,  849,  330,\n",
       "          222,  272,  146,  210,  791,  791,   99,  298,  339,  437,  292,  437,\n",
       "          292,  436,  292,  304,  294,  445,  571,  423,  336,  298,  222,  437,\n",
       "          292,  437,  292,  636,  914,  387,  387,  366,  812,  336,  336,  383,\n",
       "          292,  294,  294,  849,  330,  222,  298,  339,  304,  833,  383,  664,\n",
       "          330,  222,  294,  660,  646,  294,  660,  294,  712,  336,  646,  660,\n",
       "          294,  712,  336,  646,  298,  222,  298,  339,  292,  636,  750,  146,\n",
       "          210,  791,  791,   99,  214,  812,  292,  298,  222,  636,  222,  298,\n",
       "          339,  304,  833,  383,  664,  330,  222,  294,  660,  646,  294,  660,\n",
       "          294,  712,  336,  646,  660,  294,  712,  336,  646,  298,  222,  292,\n",
       "          298,    2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = fast_tokenizer([act], env.observation['Inst2vecPreprocessedText'],\n",
    "          is_split_into_words=True,\n",
    "          padding=True,\n",
    "          truncation=True,\n",
    "          max_length=1024,\n",
    "          return_tensors=\"pt\")\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e8ca3-e0a8-47cd-9d53-14710bcda733",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "87090b43-5143-42b4-8fce-23732fc1c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "55cf9e43-a38b-45be-b20c-e29a2866a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_sampler(samples=SAMPLES, phases=PHASES):\n",
    "    # for benchmark in env.datasets[\"cbench-v1\"].benchmarks():\n",
    "    #     print(benchmark)\n",
    "        # for _ in range(samples):\n",
    "        #     env.reset(benchmark=benchmark)\n",
    "    for _ in range(samples):\n",
    "        env.reset()\n",
    "        for phase in range(phases):\n",
    "            action = env.action_space.sample()\n",
    "            _, reward, done, info = env.step(action)\n",
    "            env.action_space.to_string(action)\n",
    "            if done: break\n",
    "            action = env.action_space.to_string(action)\n",
    "            text = env.observation['Inst2vecPreprocessedText']\n",
    "            label = reward\n",
    "            yield  [action] + text, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1cee9f79-8a94-4367-80c9-64116d63372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_samples = [{\"action\": a, \"text\": t, \"reward\": r} for a, t, r in dataset_sampler(64, 8)]\n",
    "# eval_samples = [{\"action\": a, \"text\": t, \"reward\": r} for a, t, r in dataset_sampler(8, 8)]\n",
    "\n",
    "train_samples = [{\"text\": x, \"label\": y} for x, y in dataset_sampler(64, 8)]\n",
    "eval_samples = [{\"text\": x, \"label\": y} for x, y in dataset_sampler(8, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8b2122b6-c1bf-4d02-b808-1e02fb41d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {k: v for d in train_samples for k, v in d.items()}\n",
    "eval_dict = {k: v for d in eval_samples for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "07a2dbf5-aaed-45d2-807a-dd8a7a69fb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-callsite-splitting, opaque = type opaque, op...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-prune-eh, opaque = type opaque, opaque = typ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-loop-unroll-and-jam, opaque = type opaque, o...</td>\n",
       "      <td>-0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-loop-instsimplify, opaque = type opaque, opa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-inline, opaque = type opaque, opaque = type ...</td>\n",
       "      <td>-0.498452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  [-callsite-splitting, opaque = type opaque, op...       0.0\n",
       "1  [-prune-eh, opaque = type opaque, opaque = typ...       0.0\n",
       "2  [-loop-unroll-and-jam, opaque = type opaque, o... -0.003096\n",
       "3  [-loop-instsimplify, opaque = type opaque, opa...       0.0\n",
       "4  [-inline, opaque = type opaque, opaque = type ... -0.498452"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_samples).astype('object')\n",
    "eval_df = pd.DataFrame(eval_samples).astype('object')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "55bf79ac-4a07-44ea-a3fa-4b60f3693bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = Dataset.from_dict(train_dict)\n",
    "# eval_ds = Dataset.from_dict(eval_dict)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ad1b003d-e701-49d8-bfc0-4a7a882af0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39db9329307a4454b93553cd9c2afff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ec32b79f25477a80668f5e3637fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(example):\n",
    "    return fast_tokenizer(example['text'],\n",
    "                          is_split_into_words=True,\n",
    "                          padding=True,\n",
    "                          truncation=True,\n",
    "                          max_length=1024,\n",
    "                         )\n",
    "\n",
    "tokenized_train = train_ds.map(preprocess, batched=True)\n",
    "tokenized_valid = eval_ds.map(preprocess, batched=True)\n",
    "\n",
    "columns = ['input_ids', 'token_type_ids', 'label']\n",
    "tokenized_train.set_format(type='torch', columns=columns)\n",
    "tokenized_valid.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "49829401-3217-498b-b7ad-9eedf3af6f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bbe2597c-725c-4966-b5e6-2035f122fe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f6533-6500-4292-8ab4-cc8a3ae2414a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
